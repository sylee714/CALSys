from sklearn.pipeline import Pipeline
import numpy as np
import pandas as pd
import math
from sklearn.compose import ColumnTransformer
from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer
from sklearn.preprocessing import LabelEncoder
from sklearn.ensemble import RandomForestClassifier
from sklearn import metrics
from scipy.sparse import hstack
from scipy import sparse
import scipy
import matplotlib.pyplot as plt
from sklearn.metrics import confusion_matrix
import seaborn as sns

# This method converts a Series list into a sparse matrix
def convert_to_sparse_matrix(series_list):
    # Convert to a numpy array
    result = series_list.to_numpy()
    # Get the number of rows
    rows = result.shape[0]
    # Reshape the array to a 2D array
    result_2d = result.reshape(rows, 1)
    # Convert to a sparse matrix
    result_sparse = sparse.csr_matrix(result_2d)
    return result_sparse


# Columns to drop
drop_cols = ['CVE-ID', 'Patch Date', 'Exploit Date', 'ZDI Published Date', 'CWE ID']

# Read the files
positive_cases = pd.read_csv('../Files/selected_zero_day_positive_cases_with_zdi.csv')
selected_negative_cases = pd.read_csv('../Files/selected_zero_day_negative_cases_with_zdi.csv')
remaining_negative_cases = pd.read_csv('../Files/remaining_zero_day_negative_cases_with_zdi.csv')

# Drop columns that are not needed
for col in drop_cols:
    positive_cases = positive_cases.drop(col, axis=1)
    selected_negative_cases = selected_negative_cases.drop(col, axis=1)
    remaining_negative_cases = remaining_negative_cases.drop(col, axis=1)

# Replace 'NaN'
positive_cases.fillna('', inplace=True)
selected_negative_cases.fillna('', inplace=True)
remaining_negative_cases.fillna('', inplace=True)

# Convert date to datetime
positive_cases['MITRE Assign Date'] = pd.to_datetime(positive_cases["MITRE Assign Date"])
selected_negative_cases['MITRE Assign Date'] = pd.to_datetime(selected_negative_cases["MITRE Assign Date"])
remaining_negative_cases['MITRE Assign Date'] = pd.to_datetime(remaining_negative_cases["MITRE Assign Date"])

# Sort the data by the "MITRE Assign Date"
positive_cases.sort_values(by=['MITRE Assign Date'])
selected_negative_cases.sort_values(by=['MITRE Assign Date'])
remaining_negative_cases.sort_values(by=['MITRE Assign Date'])

# Compute the cut off date
cut_off_index = math.floor(positive_cases.shape[0]*.7)
cut_off_date = pd.to_datetime(positive_cases.iloc[cut_off_index, 0]) # with the filtered data
# print("Cut off index: ", cut_off_index)
# print("Cut off date: ", cut_off_date)
# print("----------------------------------------")

# ---------------------------------------------------------
# TRAINING SET
# Get the training set from the positive set
training_data = positive_cases.loc[positive_cases['MITRE Assign Date'] < cut_off_date]
# print("Training Positive Cases: ", training_data.shape)

# Get the training set from the negative set
training_data_2 = selected_negative_cases.loc[selected_negative_cases['MITRE Assign Date'] < cut_off_date]
# print("Training Negative Cases: ", training_data_2.shape)

# Combine the training sets into one
training_data = training_data.append(training_data_2, ignore_index=True)
# print("Training Cases: ", training_data.shape)
# print("----------------------------------------")

# ---------------------------------------------------------
# TESTING SET
# Get the testing set from the positive set
testing_data = positive_cases.loc[positive_cases['MITRE Assign Date'] >= cut_off_date]
# print("Testing Positive Cases: ", testing_data.shape)

# Get the testing set from the negative set
testing_data_2 = selected_negative_cases.loc[selected_negative_cases['MITRE Assign Date'] >= cut_off_date]
testing_data_3 = remaining_negative_cases.loc[remaining_negative_cases['MITRE Assign Date'] >= cut_off_date]
testing_data_2 = testing_data_2.append(testing_data_3, ignore_index=True)

# Randomly select negative cases
# The ratio is 1 positive : 32 negative
testing_data_4 = testing_data_2.sample(n=math.floor(testing_data.shape[0]*32), random_state=42)
# print("Testing Negative Cases: ", testing_data_4.shape)

# Combine the positive and negative testing data
testing_data = testing_data.append(testing_data_4, ignore_index=True)
# print("Testing Cases: ", testing_data.shape)
# print("----------------------------------------")

# Combine the training and testing data to for the td-idf vectorizers
data = training_data.append(testing_data, ignore_index=True)

# Encode the label column
Encoder = LabelEncoder()
target_col = 'Zero Day Exploit'
training_data[target_col] = Encoder.fit_transform(training_data[target_col])
testing_data[target_col] = Encoder.fit_transform(testing_data[target_col])

# Extract the label column
training_y = training_data[target_col]
testing_y = testing_data[target_col]

# Lists to save results
ngrams = []
accuracies = []
precisions = []
recalls = []
f1s = []

# Convert the strings to floats
training_data["Severity Score"] = training_data["Severity Score"].astype(float)
testing_data["Severity Score"] = testing_data["Severity Score"].astype(float)
training_data["Num of CPE"] = training_data["Num of CPE"].astype(float)
testing_data["Num of CPE"] = testing_data["Num of CPE"].astype(float)
training_data["Num of Refs"] = training_data["Num of Refs"].astype(float)
testing_data["Num of Refs"] = testing_data["Num of Refs"].astype(float)

# Convert to sparse matrix
training_severity_scores = convert_to_sparse_matrix(training_data.iloc[:, 3])
testing_severity_scores = convert_to_sparse_matrix(testing_data.iloc[:, 3])
training_in_zdi = convert_to_sparse_matrix(training_data.iloc[:, 4])
testing_in_zdi = convert_to_sparse_matrix(testing_data.iloc[:, 4])
num_of_refs_col_index = training_data.columns.get_loc('Num of Refs')
training_num_of_refs = convert_to_sparse_matrix(training_data.iloc[:, num_of_refs_col_index])
testing_num_of_refs = convert_to_sparse_matrix(testing_data.iloc[:, num_of_refs_col_index])

# CWE ID one-hot encoding
# Find the starting col index
start_col_index = training_data.columns.get_loc('0')
# scipy.sparse.csr_matrix(training_data.iloc[:, start_col_index:].values)
training_cwe_id_ohe = scipy.sparse.csr_matrix(training_data.iloc[:, start_col_index:].values)
testing_cwe_id_ohe = scipy.sparse.csr_matrix(testing_data.iloc[:, start_col_index:].values)

max_feature_factor = 100
max_feature = 1300
for i in range(13):
    # Single Predictor 1-gram
    cve_tfidfvectorizer = TfidfVectorizer(
            analyzer='word',
            # max_features=max_feature,
            max_features=(max_feature_factor * (i + 1)),
            max_df=0.8,
            min_df=5,
            stop_words='english'
        )

    # Feed the cve description
    cve_tfidfvectorizer.fit(data['CVE Description'])

    zdi_tfidfvectorizer = TfidfVectorizer(
            analyzer='word',
            # max_features=max_feature,
            max_features=(max_feature_factor * (i + 1)),
            max_df=0.8,
            min_df=5,
            stop_words='english'
        )

    # Feed the zdi description
    zdi_tfidfvectorizer.fit(data['ZDI Description'])

    # Refs tf-idf
    ref_tfidfvectorizer = TfidfVectorizer(
            analyzer='word',
            # max_features=max_feature,
            max_features=(max_feature_factor * (i + 1)),
            max_df=0.8,
            min_df=5,
            stop_words='english'
        )

    # Feed the refs
    ref_tfidfvectorizer.fit(data['Refs'])

    # Transform training and testing descriptions
    cve_train_x = cve_tfidfvectorizer.transform(training_data['CVE Description'])
    cve_test_x = cve_tfidfvectorizer.transform(testing_data['CVE Description'])
    zdi_train_x = zdi_tfidfvectorizer.transform(training_data['ZDI Description'])
    zdi_test_x = zdi_tfidfvectorizer.transform(testing_data['ZDI Description'])
    ref_train_x = ref_tfidfvectorizer.transform(training_data['Refs'])
    ref_test_x = ref_tfidfvectorizer.transform(testing_data['Refs'])

    # Combine all the features
    train_x = hstack((cve_train_x, zdi_train_x, training_severity_scores, training_in_zdi, ref_train_x,
                      training_num_of_refs, training_cwe_id_ohe))
    test_x = hstack((cve_test_x, zdi_test_x, testing_severity_scores, testing_in_zdi, ref_test_x,
                     testing_num_of_refs, testing_cwe_id_ohe))

    # Fit the training dataset on the RF
    model = RandomForestClassifier(random_state=42)
    model.fit(train_x, training_y)

    # Predict the labels on validation dataset
    predictions = model.predict(test_x)

    y_test = testing_y.tolist()
    accuracy = metrics.accuracy_score(y_test, predictions)
    precision = metrics.precision_score(y_test, predictions)
    recall = metrics.recall_score(y_test, predictions)
    f1 = metrics.f1_score(y_test, predictions)

    # Confusion Matrix
    cf_matrix = confusion_matrix(y_test, predictions)

    ngrams.append(max_feature_factor * (i + 1))
    accuracies.append(accuracy)
    precisions.append(precision)
    recalls.append(recall)
    f1s.append(f1)

    print("1-Gram Result")
    print("Max Feature: ", max_feature_factor * (i + 1))
    print("Accuracy: ", accuracy)
    print("Precision: ", precision)
    print("Recall: ", recall)
    print("F1: ", f1)
    print("Confusion Matrix: ")
    print(cf_matrix)
    print("----------------------------")

fig, ax = plt.subplots()

ax.set(xlim=[0.0, 1300], ylim=[0.0, 1.05],
       xlabel='N-Grams',
       ylabel="Metrics",
       title="Metrics vs N-Grams")

ax.plot(ngrams, accuracies, label="Accuracy", linestyle='-')
ax.plot(ngrams, precisions, label="Precision", linestyle='--')
ax.plot(ngrams, recalls, label="Recall", linestyle='-.')
ax.plot(ngrams, f1s, label="F1", linestyle=':')
ax.legend(loc="upper left")
plt.show()

ax2 = sns.heatmap(cf_matrix/np.sum(cf_matrix), annot=True, fmt='.2%', cmap='Blues')
ax2.set_title('Confusion Matrix \n\n');
ax2.set_xlabel('\nPredicted Values')
ax2.set_ylabel('Actual Values ');

## Ticket labels - List must be in alphabetical order
ax2.xaxis.set_ticklabels(['False','True'])
ax2.yaxis.set_ticklabels(['False','True'])
plt.show()
